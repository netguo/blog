如果Redis，采用单机部署，在实例宕机的情况下，等实例恢复需要一定时间，此时会造成服务不可用。如果磁盘故障，还有可能导致数据全部丢失。Redis可靠性保障，主要两个方面：不可用时间尽量短，数据尽量少丢失。那Redis有什么解决方案呢？
### 主从复制
redis的主从复制命令/配置文件，常用：
```
--slaveof {masterHost} {masterPort } 建立复制
slaveof no one 断开复制
slave-read-only=yes 从节点只读
repl-disable-tcp-nodelay no 控制是否关闭TCP_NODELAY
```
#### 主从复制模型

- 一主一从：最简单的拓扑结构，主节点出现故障，可以故障故障转移到从节点。
- 一主多从：多个从节点，带来更多容错性。从节点过多，主节点会做数据同步，会对主节点造成性能影响。主要fork子进程、网络带宽。
- 主从从集联模式：从节点过多会对主节点造成性能影响，可以设置部分从节点与从节点同步。

主从库可以采用读写分离形式，可以降低主节点的压力，例如一些keys，sort命令，不过从节点数据同步有一定的时间差。主要看使用场景。
#### 主从复制流程
##### 全量同步
![image.png](https://cdn.nlark.com/yuque/0/2024/png/8364057/1712728412128-e74a2b74-f368-4c3d-b10f-0014504bc93f.png#averageHue=%23eff5e8&clientId=u5ca6c0c7-af7b-4&from=paste&height=838&id=u7868e3ff&originHeight=1676&originWidth=3765&originalType=binary&ratio=2&rotation=0&showTitle=false&size=1282708&status=done&style=none&taskId=u025e8bc8-bb55-4bff-9493-f0c587ea3ef&title=&width=1882.5)

- 主从库协商：从库执行slaveof后，通过psync命令，告知主库需要全量同步。主库收到命令之后，用FULLRESYNC响应命令带上两个参数：主库 runID 和主库目前的复制进度 offset，返回给从库。用于后续增量同步。
- 主库同步数据给从库：主库先执行bgsave生成RDB文件，后把RDB文件发送给从库。从库收到RDB文件后，熟悉清空现有数据，然后加载RDB文件。
- 同步过程新生成的数据：在主从全量同步的过程中，主库如果还有数据写入，主库写入命令缓存的repl buffer中，全量同步完成后，主库发送repl buffer中的数据给到从库。
- 全量同步完成后，主库后续收到的命令会陆陆续续同步给到从库，这个过程也称作基于长链接的命令传播。

主从同步是比较耗时的操作，按照经验来讲，6G的数据大概需要2分钟。这个过程，需要注意两个参数配置repl-timeout，主从同步时间，如果超过则放弃同步。client-output-buffer-limit replica，控制同步过程中缓存去大小，如果超过配置则主从全量同步失败。
##### 增量同步
增量同步，针对主从运行过程中，如果出现网络闪断的场景。如果此时需要全量复制，复制成本较高，可以通过增量同步的方式。
![image.png](https://cdn.nlark.com/yuque/0/2024/png/8364057/1712729235091-03b9bd33-98a8-4dd8-84f3-5dc55def1945.png#averageHue=%23eef5e7&clientId=u5ca6c0c7-af7b-4&from=paste&height=845&id=uac2fac07&originHeight=1689&originWidth=3328&originalType=binary&ratio=2&rotation=0&showTitle=false&size=929911&status=done&style=none&taskId=ub4ce2a18-dda7-476d-8b1c-5144c519650&title=&width=1664)

- 主从库协商：连接恢复后，从库通过psync命令告知到主库，自己现在复制的进度。
- 数据同步：主库的repl backlog是一个环形缓冲区，主库先判断从库的offset是否已经被覆盖，如果已经被覆盖，那么就需要全量同步。如果没有被覆盖，同步offset后的数据。

缓行缓冲区大小，可以通过repl_backlog_size来设置。
### 故障转移
redis实现了主从机制，如果主宕机，就可以通过故障转移，转移到从节点，从节点提供服务。redis主要通过哨兵机制来实现。
#### 哨兵机制
哨兵机制负责主从的故障转移，主要负责的就是三个任务：监控、选主、通知。

- 监控：哨兵通过周期性的给所有的主从库发送ping命令，检测是否在线。
- 选主：哨兵判断主库挂了，会按照一定规则选择一个从库的实例，作为新的主库。
- 通知：哨兵会把新主库的信息告知到其它从库，从库会和新主库建立连接，并做数据复制。
##### 主观下线和客观下线
如果哨兵和主库之间存在网络问题，那么哨兵会出现误判，那么怎么解决呢。哨兵以集群的模式部署，所有哨兵进行商议确定，主库是否已经下线。

1. 一个哨兵判断主库下线，判断主库为“主观下线”，此时哨兵会跟其它哨兵协商。
2. 协商过程类似分布式共识算法。
3. 如果有M个(可配置，建议N/2+1)个哨兵判断主库“主观下线”，那么哨兵集群就会判断主机“客观下线”，执行后续故障转移过程。
##### 主库选择规则

1. 筛选，筛选出在线，且网络状态良好的从库。redis有对网络断链有专门记录，如果断链超过一定次数，则不适合作为后续主库。
2. 打分，选出可以作为选主的从库后，对它们进行打分。打分规则：从库优先级、从库复制进度、从库ID。优先级通过slave-priority配置，通常如果有性能更好的从库会做设置。如果优先级都相同，那么根据从库的复制进度，如果复制进度相同，那么就选择最小ID的从库。

主从切换是需要一个时间过程，此时是不可用的，如果客户端希望切换过程保持高可用，读从库，写操作可以先写入缓存或者消息队列。
#### 哨兵集群的高可用
哨兵负责Redis的故障转移，如果哨兵单机部署，哨兵本身出问题那么会对Redis集群的故障转移是致命的影响，所以哨兵也是需要集群部署。
哨兵主要负责客户下线，哨兵之间需要相互建立连接并通过分布式协调达成共识。那么我们需要关注几个问题，哨兵之间的服务发现机制，哨兵与Redis主从的服务发现机制，客户端怎么知晓主从切换。
![哨兵集群.png](https://cdn.nlark.com/yuque/0/2024/png/8364057/1712978807211-151f64b3-a187-4d30-b900-127aeb1ff1cf.png#averageHue=%23faf9f8&clientId=u414e6fc4-c616-4&from=ui&height=350&id=u40289c0e&originHeight=491&originWidth=731&originalType=binary&ratio=2&rotation=0&showTitle=false&size=43411&status=done&style=none&taskId=ud22d920a-5265-4a7f-973a-e143ebfa6e3&title=&width=521)

- 哨兵之间相互发现，是通过发布订阅实现的。哨兵都订阅了主节点的一个特殊的channel，有哨兵上线会通过该频道发布信息，其它哨兵订阅该频道感知到新的哨兵上线，并与新的哨兵建立连接。
- 哨兵是个集群，并没有主从之分，当需要客观下线时通过选举确定执行客户下线的哨兵，去执行后续主从切换操作。
- 哨兵发现从节点，也是通过给Redis主节点发送INFO命令，获取从节点信息，并建立连接，监控从节点。
- 客户端感知主从切换，也是通过发布订阅实现，通过订阅哨兵一个特殊频道，感知具体的主从切换。
### Redis集群
redis主从切换，已经实现了故障转移。在数据量比较大的情况下，如果Redis规模增大，那么可以通过增加内存配置实现，但是随着redis内存变大，每次进行fork的时间就会变长，其次硬件也会有瓶颈。该场景可以通过redis的集群（Redis Cluster）来支持，通过数据横向切片，数据分布在不同的节点上。
#### 哈希槽
Redis集群的哈希槽共16384个（0-16383），这些槽会均匀的分布在集群中实例。数据的读写，需要先找到具体的槽hash(key)取模16384，然后再根据具体的槽找到对应的redis机器。在机器中对具体的槽中做相应的数据读取。
##### 为什么需要槽？
Redis集群是去中心化的分布式架构，在新增/删除节点时，需要数据迁移，可以以槽的方式迁移，保证数据均衡和迁移过程的均衡性。可以理解为一致性哈希的模式。
##### 哈希槽为什么是16384？
Redis集群之间是通过Gossip协议来交换元数据，每个Redis节点的槽信息也属于元数据。Redis是用位图来存储槽信息的，如果集群数量比较大的情况下，再大的槽数量会对网络造成阻塞。
#### 集群扩/缩容
Redis集群新增节点是不需要停机服务的。
##### 集群扩容
假如目前有三个节点，需要新增一个节点。

- 节点A的槽：0-5460
- 节点B的槽：5461-10921
- 节点C的槽：10922-16383

此时新增一个节点D，之前每个节点的槽数量为5461/5462，四个节点后每个节点槽的数量为4096，那么会从节点A、B、C分别迁移1365/1366槽数据到节点D，保证新增节点的后数据均衡。
##### 客户端如何知晓
首先客户端是维护着槽和节点的对应信息，Redis Cluster提供一种重定向的方案。
还是以刚刚示例，假如节点A的5000槽迁移到节点D，此时客户端访问5000槽时，还是访问到A节点。节点A会返回：(error) MOVED 5000 D (ip:port)，此时客户端再去访问D即可，并更新自己维护的槽信息。
还有个场景，假如此时5000这个槽正在迁移过程中，节点A会返回，(error) ASK 5000 D (ip:port)。此时客户端通过发送ASKING命令到D，读写迁移到一半的槽数据。
#### 故障转移
##### 故障发现
集群之间通信时通过Gossip协议，ping/pong消息来交换元数据。下线分为主观下线和客户下线，只有半数以上认为某个节点已经下线，才会执行后续节点下线操作。
##### 故障转移
Redis的故障转移是通过节点主从架构实现的，判定节点下线，需要从节点对应的从节点中选取一个从节点作为主节点。此时选举并不是哨兵执行，是其它主节点通过分布式共识算法选取。
Redis Cluster认为一个槽找不到对应的节点，就默认集群不可用，所以在选主过程中，集群是不可用的。

