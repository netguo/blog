## 一、发展和起源
Apache Cassandra 是一个开源的、分布式、无中心、弹性可扩展、高可用、容错、一致性可调、面向行的数据库，它基于Amazon Dynamo的分布式设计和Google Bigtable的数据模型。它具备以下特性：

- 分布式和去中心化
- 弹性可扩展
- 高可用和容错
- 可调节的一致性
- 灵活的Schema
- 高性能

Cassandra起源于2007年，已经发展十几年，有活跃的开源社区。目前已经在上千家公司使用，包括众多互联网巨头，例如苹果，eBay，饿了么等。

- 2007年Facebook 为了解决消息收件箱搜索问题（ Inbox Search problem）而开始设计 Cassandra 项目。
- 2008年7月 Cassandra 的代码被作为开源项目发布到 Google Code。虽然代码在2008年作为 Google Code 的一个项目，但是这段时间基本上只有 Facebook 工程师来更新代码，基本上没有形成社区。
- 2009年3月，Cassandra 被转移到 Apache 孵化器项目。
- 2010年2月，它被投票成为一个顶级项目。后续陆续众多公司的开发者参与进来，包括Twitter，LinkedIn，Apple，其中还包括了许多独立开发者。
- 2010年4月，成立了DataStax公司，发展商业化版本。
## 二、Cassandra的应用
### 2.1 数据模型及实践
#### 数据类型
|数据类型|说明|
| --- | --- |
| 数字数据类型 |int：32位有符号整型<br>bigint：64位长整型<br>smallint：16位有符号整型<br>tinyint：8位有符号整型<br>varint：可变精度有符号整数<br>float：32位 IEEE-754 浮点型<br>double：64位 IEEE-754 浮点型<br>decimal：可变精度的decimal |
| 文本数据类型 | text, varchar：UTF-8编码的字符串ascii：ASCII字符串 |
| 时间和标识符数据类型 | timestamp：时间戳date<br> time：时间类型，分别表示日期和时间。<br>uuid：通用唯一识别码（universally unique identifier，UUID）是128位数据类型，type 4 UUID，其实现完全是基于随机数的。<br>timeuuid：这个是 Type 1 UUID，它的实现基于计算机的 MAC 地址，系统时间和用于防止重复的序列号。 |
| 集合数据类型 | set、list、map |
| 自定义数据类型 | Cassandra 中如果内置的数据类型无法满足我们的需求，我们可以使用自定义数据类型的功能。 |

#### 数据模型
| Keyspace | 可以类比为库的概念 |
| --- | --- |
| Column Family | 可以类比为表的概念，一个列族 |
| Row  key | 一行数据的key，（(分区键,..)，聚类键,..))，查询条件需要按照键顺序查询，可类比聚合索引。<br>底层物理存储是按照row key排序的。 |
| Column name | 列名，最大为64KB |
| Column value | 列值 |

#### 最佳实践

- 围绕查询来设计列族
- 选择合适的row key提升读性能，防止数据倾斜
- 通过反范式化和冗余提高读性能
- column name尽量简短，减少存储
- column name存储数据，column value设置为空
- 确保数据的row key是唯一的，否则会被覆盖
- 确保操作是幂等的，Cassandra保证的最终一致性，会有重试操作
- 读多，写多的数据可以考虑做分离
- 预先设计好合适的TTL，一旦设置后很干改变。
- super columns不支持二级索引，有限使用Composite column

### 2.2 Cassandra的实现机制
#### 数据存储

- Cassandra通过一致性哈希环，把数据分为多个虚拟节点和物理节点
- 通过分区键的哈希决定在哪个分区存储
- 同一个分区键不同的Row数据按照聚类键进行顺序存储，如果有多个聚类键，按照聚类键顺序，进行排序。
- 同一Row，不同的列，根据列名称的字典数据进行数据存储。
- 底层物理存储采用LSM树机制
#### 写数据机制
采用LSM树机制

1. 写WAL日志，采用日志追加方式
2. 写内存数据，Memtable，内存中数据已经做过排序
3. Memtable数据满了，写入磁盘SSTable
4. SSTable写入成功后，WAL数据可删除
5. SSTable数据定期合并

数据复制

- Cassandra中每个节点都可作为协调节点处理客户端请求
- 如果复制因子是3，那么会有3个节点存储数据，数据节点和它两个邻居节点
- 协调节点直接向数据节点和它两个邻居节点写数据
- 双机房复制，协调节点之间复制
#### 读数据机制

- 先访问Memtable数据
- Memtable查询不到，再查询缓存，在数据读取后加入缓存。
- 缓存查询不到，查询SSTable
- 查询SSTable的方式布隆过滤器，一级索引，二级索引，SSTable
- 建立的两级索引，防止索引文件太大，占用内存太大。
- 企业版索引采用字典树实现。
#### 数据一致性

- Cassandra注重的是可用性，对可用性做了优化，一致性提供灵活的选择性。
- 一致性级别CL，可以分为读写一致性。
- 写一致性，协调者写数据时，收到几个节点的ACK。ONE、QUORUM、ALL....。
- 读一致性，客户端通过协调者读数据时，多少节点写入才能读取。

**读修复**

- 读一致性为ALL时，协调者读取数据，如果有节点数据不一致，有概率性修复落后节点的数据。
- 协调者会从一个节点读取数据，从另外两个节点读取数据校验和。
- 如果有数据不一致，会读取三个节点数据，返回最新的数据。并修复数据落后的节点。
- 修复是概率性的，可以配置。
#### 压实
Cassandra底层数据存储采用SSTable，数据是不可变的。那必定会存在很多过期的数据，被删除的数据，被更新的数据。所以SSTable数据需要定期的压实，减少数据存储，其次也能提高读性能（减少访问磁盘次数）。Cassandra3.0支持的压实策略如下：

- STCS 规模分层压实策略：默认的压实策略，其它策略不适合时作为后备。基本思想是是合并大小大致相同的sstable放到到一个桶，最终选择合并哪个桶，是根据哪个桶的sstable的读取最高。
- LCS 水平压实策略。针对读取繁重的工作负载或具有大量更新和删除的工作负载进行了优化。进行分层压缩，确保每层的SSTable不重叠，具备读取确定性。具体步骤，L0不保证数据不重复，向L1合并时保证L1数据是有序的。L1到达阈值后，选取一个L1文件向L2合并。后续类似。
- TWCS 时间窗压实策略。按照时间窗口进行压实。可以有效的处理带时间窗口的数据，及时处理带TTL的过期数据。

压实类型

- Minor compation 轻微压实：自动触发
- Major compation 大压实：用户对节点上所有的SSTable执行压实。
- User defined compation 用户定义的压实：用户对给定的SSTable集合进行压实。
- Scrub 磨砂：尝试修复任何损坏的SSTable。
- UpgradeSSTables：升级SSTable到最新版本。
- Cleanup 清理：删除节点不在拥有的任何范围。
- Secondary index rebuild 二级索引重建：重建二级索引。
- Anticompaction 反压实：修复范围从存在的SSTable中分离出来。
- Sub range compaction：压缩指定的子范围。
#### 墓碑
Cassandra的删除操作不会删除数据，会生成一个墓碑数据。为什么需要墓碑数据呢，在节点故障时，例如删除A，三个节点的状态为[],[],[A]，节点1宕机，数据恢复会恢复成[A],[A],[A]。

- 从磁盘中删除数据和墓碑，Cassandra代码还需要遵循其他安全规则。需要一行或一个分区的所有碎片都在同一个 Compaction 中，墓碑才能被删除。
- 墓碑不被移除可能意味着使用了大量的磁盘空间，读取速度较慢，维修工作较多，GC压力较大，需要更多的资源等等。

通过‘gc_grace_seconds’参数确定多久时间后，压缩操作会将墓碑数据进行删除。

## 三、Cassandra的发展和对比
### Cassandra的发展
Cassandra4.0新特性

- **审核日志（Audit Logging）**：可以将数据库的所有活动记录到本地文件中，包括身份验证以及所有的 CQL 请求（无论成功与否）。
- **零拷贝串流（Zero-Copy Streaming）**：在串流时无需将数据读到内存后再写入网络，发送方和接收方可以直接通过网络发送和接收数据。大大提升传输速度。避免了相关对象的创建，减少了对 GC（垃圾回收）的压力。
- **Netty 节点间通信**：将旧版本中根据集群节点分配线程的架构改为 Netty，I/O 变为非阻塞的，不再按节点分配线程。延迟更低（平均值减少 40%，99 分位的延迟减少了 60%），吞吐量更高（约提升 2 倍），并且内存占用更少。
- **虚拟表（Virtual Tables）**：用户能够以与操作其他 Cassandra 表相同的方式使用这些虚拟表，方便操作人员访问和管理相关数据。
- **增量式修复改进**：重写了增量反熵修复算法的基础部分，能更高效地保持数据副本的同步，优化了增量修复操作，在提高效率的同时确保数据副本之间的一致性。
- **临时副本（Transient Replication）**：此特性使得在某些情况下数据的复制和管理更加灵活。
- **支持 Java 11**：采用了 Java 11 的 ZGC（Z Garbage Collector）垃圾回收算法，可将垃圾回收器的暂停时间减少到几毫秒，优化系统性能。

Cassandra5.0新特性

- **统一压缩策略（Unified Compaction Strategy）**：融合了分层和水平压缩策略的优点，并增加了分片功能。其创新的分片机制确保了高效的并发压缩，同时保持 SSTable 之间不重叠，从而提高了性能并简化了部署管理。
- **存储附加索引（Storage Attached Indexes）**：提供了极快的数据检索速度，能够以前所未有的速度和效率访问所需信息。
- **Trie 内存表和 Trie 索引 SSTables**：基于 Trie（前缀树）和数据库键的字节可比较表示，改进了修改操作的性能和数据查找（读取）的性能，同时减少了给定数据量的结构大小。
- **新的数学 CQL 函数**：包括`abs`、`exp`、`log`、`log10`和`round`等。
- **向量搜索（Vector Search）**：利用存储附加索引和密集索引技术，改变了数据探索和分析的方式，对机器学习和人工智能等领域有重要影响。
- **动态数据掩码（Dynamic Data Masking）**：引入了新的动态数据掩码功能，允许使用称为掩码列的概念来隐藏敏感信息。
- **其他特性**：支持 JDK 17；提供了更多的保护措施和扩展的 TTL；增加了新的向量数据类型；具备用于识别大分区的工具；支持 Microsoft Azure；包含 CIDR 授权器；可使用可插拔的加密提供程序；拥有用于系统日志的虚拟表等。
### Cassandra和Hbase的区别
|  | Cassandra | Hbase |
| --- | --- | --- |
| 高可用 | 无中心无单点 | HDFS单点故障 |
| 故障恢复时间 | Quorum无影响 | Region重新分配/MTTR时间长 |
| 读写性能 | 快 | 相对慢 |
| 一致性 | 最终一致性 | 强一致 |
| 数据恢复机制 | Hintedhandoff 读修复 | 依赖HDFS块，读修复 |


