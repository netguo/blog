## 一、Kafka起源
### 起源
Kafka 起源于 LinkedIn。大约在 2010 年前后，LinkedIn 为了适应不断增长的用户量和系统复杂度，将系统架构从原来的单体应用转变成多个微服务。微服务之间需要执行多种类型的数据处理与分析，比如业务系统和应用程序性能监控，以及用户数据处理等，这导致需要一个中间层来解决实时访问数据的问题。
起初，LinkedIn 使用了 ActiveMQ，但发现它无法完全满足需求，经常出现消息阻塞或者服务无法正常访问等问题。于是，LinkedIn 工程师便着手开发了 Kafka。
Kafka外在表现很像消息系统，允许发布和订阅消息流，但是它和传统的消息系统有很大的差异：
1、Kafka是个现代分布式系统，以集群的方式运行，可以自由伸缩。
2、Kafka可以按照要求存储数据，保存多久都可以。
3、流式处理将数据处理的层次提示到了新高度，不仅仅是一个消息中间件，同时它是一个流平台，这个平台上可以发布和订阅数据流。
### 目前主流消息中间件比对

- Kafka：百万级别并发，分布式系统，高性能高可靠，支持多客户端语言。配置和运维要求高。
- RocketMQ：十万级别并发，分布式系统，高性能高可靠，支持消息的顺序性，支持事务消息，支持按照时间消息回溯，支持多种消息过滤模式，在阿里有广泛应用。
- RabbitMQ：万级别的并发，单机模式，功能丰富，支持多客户端语言。
- Pulsar：百万级别并发，运维成本低，成熟的应用案例较少。
## 二、Kafka的生产消费全流程
![35d3bd71bad045dd92d5a117c71e1368.png](https://cdn.nlark.com/yuque/0/2024/png/8364057/1719372735594-d0c504ef-b251-4c10-823c-e187b5dc1e97.png#averageHue=%23f8d48f&clientId=ud40f1130-52ae-4&from=paste&height=260&id=u65ad3c07&originHeight=520&originWidth=1199&originalType=binary&ratio=2&rotation=0&showTitle=false&size=80463&status=done&style=none&taskId=ua8acaf21-3f3f-48a1-8b53-cf296248b2b&title=&width=599.5)
### 基本概念
**主题**
kafka里消息是通过主题进行分类，可以类比数据库中的表。
**分区**
一个主题下可以被分为若干个分区，可以通过不同的分区策略来实现。
消费者群组
同一个主题，可以由不同的消费者群组隔离消费，互不影响。
**偏移量**
偏移量是一种原数据，是一个不断递增的整数值，在每个分区里消息偏移量是唯一的。消费者可以通过偏移量的机制，保证消息正确消费。
**Broker**
一个独立的kafka服务器叫Broker。多个Broker可以组成一个集群。
**备份**
Kafka每个主题，每个分区支持多备份。kafka通过raft协议实现。
### 生产者
**序列化**
Kafka的客户端默认提供了ByteArraySerializer,IntegerSerializer,StringSerializer，也可以实现自定义的序列化器。自定义的序列化器往往比较脆弱，容易出现兼容性问题。可以考虑开源的与语言无关的序列化框架，例如Protobuf、Avro、Thrift等。
**分区器**

* DefaultPartitioner ：默认分区器 
  - 如果消息中指定了分区，则使用。
  - 如果未指定分区但存在key，则根据序列化key使用murmur2哈希算法对分区数取模。
  - 如果不存在分区或key，则会使用粘性分区策略。 

* UniformStickyPartitioner 
  - 纯粹的粘性分区策略，统一都用粘性分区来分配。
* RoundRobinPartitioner 
  - 如果消息中指定了分区，则使用。
  - 将消息平均的分配到每个分区中，与key无关。

粘性分区策略：
> 生产者在发送消息时，为了减少网络请求会先放在一个批次（ProductBatch）里，批次必须满或者到指定时间，批次才会发送。如果发送消息较少，那各个批次都不会满，意味更高的延迟。
> 粘性分区策略会把消费先放到同一个批次，该批次对应一个分区，该批次发送后，随机选一个批次和分区。

**批次**
生产者在发送消息时，消息会先写入到一个缓冲区，消息达到缓冲区上线或者达到指定时间时，消息会统一发送。该方式有两个优势：

- 减少IO开销
- 减少GC，Kafka实现采用了缓冲池的机制。比如缓冲池默认是32M，会划分为N个内存块，一个内存块16KB。创建一个Batch，从缓冲池取一个Batch，用完后回收。

**发送策略**

- 发送并忘记：调用不做任何处理，大多数情况消息不会丢，会有重试机制。
- 同步发送：调用时返回Future对象。
- 异步发送：通过Callback回调函数获取调用情况。

**ACK**
多个分区的备份接收到消息，常用0，1，all/-1。1指的分区leader接收到信息，all指的是ISR中分区副本都接收到消息。
**生产者配置**

| key.serializer | key序列化方式 |
| --- | --- |
| val.serializer | value序列化方式 |
| ack | 0、1、all/-1 |
| buffer.memory | 生产者内存缓冲区大小，如果生产消息速度大于发送到服务端速度，那么缓存可能被填满，send方法会先被阻塞，阻塞到一定时间，会抛异常。阻塞时间由max.block.ms控制。 |
| max.block.ms | 在上面buffer.memory已经讲述 |
| compression.type | 默认情况下，消息发送时不会被压缩。该参数可以设置为snappy、gzip或lz4 |
| retries | 重试次数，生产者从服务器收到错误可能是临时性错误，retries决定了重发消息的次数，默认重试间隔100ms，可通过retry.backoff.ms控制 |
| batch.size | 当多个消息发送到同一个分区时，生产者会把这些消息放到同一个批次中。该参数表示：一个批次可使用的内存大小，单位字节，默认16K。 |
| linger.ms | 发送批次之前等待的时间，生产者会在batch.size满或者等待时间达到linger.ms，发送批次数据 |
| max.request.size | 发送请求的最大，一次请求可以是单消息，也可以是一批次。broker端也有自己限制，最好配置相同。 |
| receive.buffer.bytes | tcp socket接受数据包缓冲区大小 |
| send.buffer.bytes | tcp socket发送数据包缓冲区大小 |
| client.id | 服务器会用它来标示消息来源 |
| max.in.flight.requests.per.connection | 生产者收到服务器响应之前，可以发送多少个消息，设为1可以保证消息顺序写入服务器 |
| request.timeout.ms | 生产者在发送数据时等待服务器的响应时间 |
| metadata.fetch.timeout.ms | 生产者从服务器获取元数据时，等待响应时间 |
| timeout.ms | broker等待同步副本返回消息确认的时间 |

### 消费者
**消费者偏移量提交**
消费者采用poll来获取消息，消费成功后提交偏移量，告知kafka服务器自己的消费进度。kafka支持的提交模式：自动提交、手动提交。
自动提交，消费者在轮询消息时，会检查是否有需要的提交，判断条件通过控制自动提交的时间间隔来控制自动提交的频次。
自动提交有丢消息和重复消费的风险，在分区再平衡的过程中，如果消息还未处理，偏移量已经被提交，那么消息将会丢失。如果消息已经处理，偏移量未提交，那么消息会重复消费。
**群组协调**
群组协调的主要作用是为一个群组的消费者分配消费者，新的消费者加入或者消费者下线时，消费再均衡。实现群组协调，主要有三个角色：

- 组协调器：Kafka服务端维护，在broker启动时创建，每个实例负责维护部分消费组。负责维护与消费者心跳，选举消费者协调首领，处理离开/加入的消费者，再平衡后同步新的分配方案，管理消费者已消费的偏移量。
- 消费者协调器：向组协调器发送入组/离组请求，跟组协调器保持心跳，跟组协调器提交消费偏移量。
- 消费者协调器首领：首个加入消费者协调器作为首领，分区再平衡时负责重新调整分区。

组协调器存放消费者偏移量，在broker的_consumer_offsets文件中，默认会创建50个，根据group_id的哈希取模，决定哪个文件。
_为什么需要一个首领？_
_消费者协调器首领负责执行分区的分配工作，然后将分配结果发送给组协调器，组协调器再把分配结果返回给其他消费者的消费者协调器。这样的方式可以避免所有消费者都直接与服务端进行复杂的分区分配交互，从而减轻了 Kafka 集群的压力。_
_有哪里分区策略？_

- _Range：连续分配_
- _RoundRobin：顺序分配_
- _StickyAssignor：第一次顺序分配，再均衡时尽量保持分区跟上次一致。_
- _自定义_

**分区再均衡**
kafka客户端支持对分区再均衡事件的监听，可以再事件监听中处理一些事情。例如再均衡之前，提交偏移量。再均衡之后手动指定偏移量。
**消费者参数配置**

| fetch.min.bytes | 消费者从服务器获取的最小字节数，broker收到请求后等待消息达到该大小，返回给消费者。 |
| --- | --- |
| fetch.max.wait.ms | 指定broker的等待时间，默认是 500ms。如果没有足够的数据流入Kafka，消费者获取最小数据量的要求就得不到满足，最终导致500ms的延迟。 |
| max.partition.fetch.bytes | 服务器从每个分区返回给消费者的最大字节数 |
| session.timeout.ms | 该属性指定了消费者在被认为死亡之前可以与服务器断开连接的时间，默认是3s。如果消费者没有在session.timeout.ms指定的时间内发送心跳给群组协调器，就被认为已经死亡，协调器就会触发再均衡，把它的分区分配给群组里的其他消费者。 |
| heatbeat.interval.ms | 指定消费者poll方法向服务器发送心跳的间隔时间，一般是session.timeout.ms的三分之一 |
| auto.offset.reset | 指定消费者在读取一个没有偏移量或者偏移量失效的分区时该如何处理，默认是lastest，可配置earliest。 |
| enable.auto.commit | 是否自动提交偏移量，可通过auto.commit.interval.ms指定自动提交频率 |
| partition.assignment.strategy | 分区分配给消费者的分配策略 |
| client.id | 消费者唯一标识 |
| max.poll.records | 单次poll最大记录数 |
| receive.buffer.bytes 和 send.buffer.bytes | socket的的tcp缓冲区，-1为操作系统默认 |

## 三、服务端的高性能和高可靠
### 高可靠
**集群**
kafka的高可靠主要通过集群和分区副本来实现。kafka有两种集群模式，一种是依赖zookeeper实现分布式协调，最新版本中kafka实现了raft协议kraft，通过kraft实现分布式协调。两种方式都是为了实现分区的备份，选主等分布式协调。
kafka集群有三种角色：

- Broker节点：Kafka中的工作节点，充当消息队列的角色。
- Controller节点：即控制器节点，是集群中的特殊节点，负责储存和管理整个集群元数据和状态，它能够监控整个集群中的Broker，在需要时还能够进行平衡操作。
- 混合节点：即同时担任Broker和Controller节点角色的节点。

**ISR**
kafka数据同步一致性，并不是通过一半以上的策略，而是所有的节点都已经同步消息后才会commit消息，这种策略会导致消息提交效率较低。为此引入了ISR机制，为了防止部分副本同步过慢，影响性能，通过ISR动态维护同步较快的跟随者。

- ISR(In-Sync Replicas )：与leader保持同步的follower集合
- AR(Assigned Replicas)：分区的所有副本

ISR的动态策略，是通过延迟时间和延迟条数来作为条件。
**水位**
kafka对于水位主要有两个定义，HW和LEO。

- HW：所有ISR中同步最慢的，offset的下一位。消费者只能消费HW之前的消息。
- LEO：最新的消息的下一位，每个分区都有自己的LEO，HW通过取所有分区的LEO的最小值获取。

HW不仅仅是定义了消息的可见性，在故障恢复时也会使用到。

- follower宕机后恢复，先删除HW之后消息，在跟leader同步。
- leader宕机后，选出最大的leo作为leader，follower删除HW之前的消息，再跟leader同步。

分布式一致性协议只能保证消息的最终一致性，不能保证消息不丢失，如果需要保证消息不丢失还需要通过ack，Isr最少个数等机制。
### 高性能
kafka的高性能主要通过磁盘顺序写，零拷贝、缓冲区等机制。

