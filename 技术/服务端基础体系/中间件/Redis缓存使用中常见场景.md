### 数据一致性
数据一致性，指的是保证缓存和数据库中的数据一致性。可能造成数据不一致的场景，主要是在在数据变更（增删改）过程中。
#### 新增数据
新增数据场景比较简单，数据直接写到数据库中，不对缓存做任何操作。
#### 更新数据
1. 先更新缓存，再更新数据库
如果是先更新缓存，再更新数据库。缓存更新成功，数据库更新失败，那么缓存中的数据就与数据库中数据不一致。
2. 先更新数据库，再更新缓存
该方案也有同样的问题，如果数据库更新成功，缓存更新失败。那么缓存和数据库中的数据不一致。
3. 更新缓存的并发问题
例如线程A，B同时更新数据M，线程A先更新数据库成功，线程B后更新数据库成功。此时数据库中存的是线程B更新的数据。线程A，B更新缓存时，线程B先更新，线程A后更新，那么缓存中存的是A更新后的数据。
所以基于更新缓存和数据库，如果出现一方更新失败造成数据不一致，以及并发问题导致的数据不一致问题。我们往往不会采用更新方案。更多的通过删除缓存来实现。
4. 先更新数据库，再删除缓存
删除缓存时，如果出错可以通过重试解决。删除缓存并不存在并发问题，最终缓存都需要删除，业务使用时，如果缓存不存在，从数据库中读取最新数据。
5. 先删除缓存，再更新数据库
先删除缓存，再更新数据库，如果数据库更新失败，通过重试解决。改方案会存在一个问题，如果在数据库删除之前，有新的读取，那么会把缓存中载入未删除的数据。解决方案是，删除完数据库后，sleep一小会，再对缓存重新删除操作。
6. 重试机制
重试的话，可以通过代码重试。可以通过消息队列重试。

删除数据，在4、5方案中已经包含，不做特殊说明。
### 缓存穿透
缓存穿透是指，请求访问在数据库中不存在的数据，此时如果客户频繁访问库中不存在数据。那么数据库压力会比较大。如果受到恶意攻击，或者不合理使用场景会击垮数据库。常见的解决方案：
#### 缓存空值
数据库中某一个key查询不到，在缓存中存人改key的空值。该方案会带来两个问题，a、需要更大的内存空间。可以对空置设置过期时间。b、更新数据时，需要考虑一致性问题。
#### 布隆过滤器
新添加布隆过滤器，会带来额外的维护成本，需要维护布隆过滤器的逻辑，且不支持数据删除/变更。适用于数据相对固定的场景、数据命中不高场景(极大减少存储访问)。
### 缓存击穿
缓存击穿，指的是一个非常热点的key，在不停的扛着大并发，这个key在失效之后，大量请求直接请求到数据库。解决方式设置key永不失效，或者通过互斥锁。
#### 互斥锁
互斥锁保证的是，key失效时，通过互斥只能有一个请求可以访问到数据库，并重新加载数据库数据到缓存。
![image.png](https://cdn.nlark.com/yuque/0/2024/png/8364057/1713520583482-76a31a1e-680b-41fe-a202-10248a1658b3.png#averageHue=%23f6f6a5&clientId=ufc9c60ad-cdd1-4&from=paste&height=402&id=u1337a683&originHeight=804&originWidth=1308&originalType=binary&ratio=2&rotation=0&showTitle=false&size=220397&status=done&style=none&taskId=u3369c4c7-1e06-4937-9a98-18f3ef998a1&title=&width=654)
通过setnx设置互斥锁，获取到锁的取加载db，没有获取到锁的sleep 50ms并重试。
#### 永不失效
永不失效，可以两种实现方式，物理和逻辑。物理层面不给缓存设置过期时间，对应的key就不会过期。逻辑层面，需要key过期之前重新构建，例如过 期时间存到key的value中，一个异步线程保证key过期之前，重新构造缓存。
### 雪崩
缓存雪崩指，由于某些原因缓存不能提供正常服务，导致大量请求直接访问存储层，导致存储集联宕机。
导致雪崩的原因主要有两个：redis发生故障宕机、缓存大面积同一时间失效。
常见雪崩问题解决方案：

- 提前预防：故障演练，演练缓存宕机后，出现的状况，并在此基础之上做预案。
- 避免雪崩：保证缓存层的可用性、缓存失效时间分开，例如可以对缓存失效时间加上一个随机时间，这样过期，重复性会比较低。
- 存储层保护：对存储层访问实现限流和降级。
### 热点Key
热点Key往往是热点事件引起的，例如秒杀，促销中热门商品，明星事件等等。大量的访问会给系统带来大量问题。常见的危害有：请求过多，缓存被打垮，后续可能会引起雪崩、流量集中，达到物理网卡上限。
#### 发现热点
##### 业务预估
针对业务提前预估出频繁访问的热点Key，当然并不是所有业务都容易预估出热点Key，可能漏掉或者预估错误。
##### 客户端统计
可以在应用中统计Key的访问次数，该方案实现简单。但是如果Key个数如果过多，容易造成内存过大，切各个客户端都需要维护，维护成本较高。
##### 服务端统计
1. Redis的monitor命令，可以监控到Redis执行的所有命令，根据命令可以统计热点key的排行榜，Facebook开源的redis-faina正是利用monitor命令，统计最近10万条命令的热点key，热点命令，耗时分布等。
该方案的问题：monitor在高并发情况下会影响到Redis性能，所以适合短时间使用；monitor是针对单机的，如果集群部署，需要进行汇总。
2. Redis的hotkey命令，redis的hotkey命令，首先需要把内存逐出策略设置成LFU。在数据量较大的情况下，该命令性能较低。
3. 自己做监控分析，例如通过TCP抓包工具插件，对数据进行抓包、分析、数据化展示。
#### 热点Key解决方案
发现热点Key常见的解决方案有：

- 热点Key缓存到客户端内存
- 热点Key访问hash到各个集群节点，例如对热点Key加入多个随机值，形成多个子Key，每个子Key都存相同的value，这样对热点Key的访问就会映射到子Key的访问，会随机到不同的集群节点。
- 读写分离，读写分离架构中，可以通过扩展多个从节点用于读，降低热点Key对Redis的压力，不过该方案会增大运维成本。
### BigKey
大Key指的是Key对应的value所占用的内存空间比较大，例如一个字符串类型存储的value过大，一个集合中存储的数据过多。字符串通常超过10kb就是大key，集合类体现在元素个数过多。
#### BigKey的危害

- 内存空间不均匀，造成数据倾斜。
- 超时阻塞，Redis是单线程，对大key操作耗时比较久，会阻塞后续操作。
- 网络阻塞，每次获取大key，产生的网络流量比较大。
- 设置的最大内存的淘汰策略，导致其他key频繁淘汰。
#### 发现BigKey

- bigkeys命令，bigkeys仅会输出，每种数据结构中的最大key。如果想要定制化分析每个数据结构超过某一个阈值的key，此命令无能为力。
- scan+debug object，debug object命令可以对key进行分析，其中也会获取到key的序列化长度。scan操作可以渐进式遍历所有的key。在scan过程中key的变化，例如新增键值，可能会遍历不到。其次相对会比较慢，可以采用pipeline方式，在从节点执行。
- 使用开源工具，redis-rdb-tools工具，支持对redis的RDB文件进行扫描分析找出大Key，优点是对线上无影响，缺点是数据实效性差。
#### BigKey的解决方案

- 数据拆分，将大key拆解成多个小key，例如一个List拆分为多个List
- 清理大key，大Key不适合redis存储，改为其它存储
- 监控内存水位，防止突然出现的大key，让我们措手不及
- 失效数据定期清理，例如集合内的数据，需要定期扫描删除失效的数据，预防大key。


