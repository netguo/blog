### 背景
MapReduce 是一个编程模型，也是一个处理和生成超大数据集的算法模型的相关实现。设计这个抽象模型的灵感来自 Lisp 和许多其他函数式语言的 Map 和 Reduce 的原语。  
MapReduce认为，再复杂的数据处理流程也无非是Map/Reduce这两个映射方式的组合。

### Map/Reduce原语
MapReduce的核心概念是将输入数据集映射到健-值对集合，然后对所有包含相同健的健-值对完成归约。MapReduce认为，再复杂的数据处理流程也无非是这两个映射方式的组合。
* 几乎所有的数据都可以映射到健值对。
* 健和值可以是任意类型。
* "不共享"数据处理平台，映射器都可以独立进行，在映射器完后，归约器也能独立工作。  
  

用户自定义的 Map 函数接受一个输入的 key/value pair 值，然后产生一个中间 key/value pair 值的集合。 MapReduce 库把所有具有相同中间 key 值 的中间 value 值集合在一起后传递给 reduce 函数。
* map函数：主节点得到输入，将输入划分为较小的数据库，再将这些数据块分布到工作节点（从节点），工作节点中对各个数据块应用相同的转换函数，然后将结果传回到主节点。
* reduce函数：主节点中根据唯一的健-值对将接收的结果进行洗牌和聚集，然后再一次重新分布到从节点，通过另一类的转换函数组合这些值。
### MapReduce模型
MapReduce 架构的程序能够在大量的普通配置的计算机上实现并行化处理。这个系统在运行时只关心: 如何分割输入数据，在大量计算机组成的集群上的调度，集群中计算机的错误处理，管理集群中计算机之间必要的通信。

该抽象模型，我们只要表述我们想要执行的简单运算即可，而不必关心并行计算、容错、数据分布、负载均衡等复杂的细节，这些问题都被封装在 了一个库里面。
#### 执行概括
通过将 Map 调用的输入数据自动分割(split)为 M 个数据片段的集合，Map 调用被分布到多台机器上执行。输入的数据片段能够在不同的机器上并行处理。使用分区函数将 Map 调用产生的中间 key 值分成 R 个不同分区(例如，hash(key) mod R)，Reduce 调用也被分布到多台机器上执行。分区数量(R)和分区函数由用户来指定。map执行的数据放入缓存，周期性的写入磁盘，reduce从磁盘中读取map的数据。

![mapreduce执行概览](../picture/bigdata/mapreduce执行概览1.png)

#### Master 数据结构
Master 持有一些数据结构，它存储每一个 Map 和 Reduce 任务的状态(空闲、工作中或完成)，以及 Worker 机器(非空闲任务的机器)的标识。
Master会存储Map生成的文件地址，并把文件地址推送给Reduce任务。

#### 容错过程
##### worker故障
master 周期性的 ping 每个 worker。如果在一个约定的时间范围内没有收到 worker 返回的信息，master 将 把这个 worker 标记为失效。所有由这个失效的 worker 完成的 Map 任务被重设为初始的空闲状态，之后这些 任务就可以被安排给其他的 worker。

##### master失效
master失效一个简单的解决办法是让 master 周期性的将自身维护数据结构的写入磁盘，即 检查点(checkpoint)。如果这个 master 任务失效了，可以从最后一个检查点(checkpoint)开始启动另一个 master 进程。然而，由于只有一个 master 进程，master 失效后再恢复是比较麻烦的，因此我们现在的实现是 如果 master 失效，就中止 MapReduce 运算。客户可以检查到这个状态，并且可以根据需要重新执行 MapReduce 操作。

##### 存储位置
在我们的计算运行环境中，网络带宽是一个相当匮乏的资源。我们通过尽量把输入数据(由 GFS 管理)存 储在集群中机器的本地磁盘上来节省网络带宽。GFS 把每个文件按 64MB 一个 Block 分隔，每个 Block 保存 在多台机器上，环境中就存放了多份拷贝(一般是 3 个拷贝)。MapReduce 的 master 在调度 Map 任务时会考虑 输入文件的位置信息，尽量将一个 Map 任务调度在包含相关输入数据拷贝的机器上执行;如果上述努力失败 了，master 将尝试在保存有输入数据拷贝的机器附近的机器上执行 Map 任务。

##### 备用任务
影响一个 MapReduce 的总执行时间最通常的因素是“落伍者”:在运算过程中，如果有一台机器花了很 长的时间才完成最后几个 Map 或 Reduce 任务，导致 MapReduce 操作总的执行时间超过预期。出现“落伍者” 的原因非常多。比如:如果一个机器的硬盘出了问题，代码出现bug等。有一个通用的机制来减少“落伍者”出现的情况。当一个 MapReduce 操作接近完成的时候，master调度备用(backup)任务进程来执行剩下的、处于处理中状态(in-progress)的任务。无论是最初的执行进程、 还是备用(backup)任务进程完成了任务，我们都把这个任务标记成为已经完成。

### 技巧

#### 分区函数
MapReduce 的使用者通常会指定 Reduce 任务和 Reduce 任务输出文件的数量(R)。我们在中间 key 上使 用分区函数来对数据进行分区，之后再输入到后续任务执行进程。一个缺省的分区函数是使用 hash 方法(比如， hash(key) mod R)进行分区。然而，有的时候，其它的一些分区函数对 key 值进行的分区将非常有用。

#### 顺序保证
我们确保在给定的分区中，中间 key/value pair 数据的处理顺序是按照 key 值增量顺序处理的。这样的顺 序保证对每个分成生成一个有序的输出文件，这对于需要对输出文件按 key 值随机访问的应用非常有意义， 对在排序输出的数据集也很有帮助。

#### Combiner函数
在某些情况下，Map 函数产生的中间 key 值的重复数据会占很大的比重，并且，用户自定义的 Reduce 函数满足结合律和交换律。  

允许用户指定一个可选 的 combiner 函数，combiner 函数首先在本地将这些记录进行一次合并，然后将合并的结果再通过网络发送出去。  

也就是说，Combiner 函数在每台执行 Map 任务的机器上都会被执行一次。一般情况下，Combiner 和 Reduce 函数是一样的。Combiner 函数和 Reduce 函数之间唯一的区别是 MapReduce 库怎样控制函数的输出。Reduce 函数的 输出被保存在最终的输出文件里，而 Combiner 函数的输出被写到中间文件里，然后被发送给 Reduce 任务。部分的合并中间结果可以显著的提高一些 MapReduce 操作的速度。

#### 输入和输出类型
MapReduce 库支持几种不同的格式的输入数据。比如，文本模式的输入数据的每一行被视为是一个 key/value pair。虽然 大多数 MapReduce 的使用者仅仅使用很少的预定义输入类型就满足要求了，但是使用者依然可以通过提供一 个简单的 Reader 接口实现就能够支持一个新的输入类型。  
Reader 并非一定要从文件中读取数据，比如，我们可以很容易的实现一个从数据库里读记录的 Reader， 或者从内存中的数据结构读取数据的 Reader。

#### 副作用  

#### 跳过损坏的记录

#### 本地执行
调试 Map 和 Reduce 函数的 bug 是非常困难的，因为实际执行操作时不但是分布在系统中执行的，而且 通常是在好几千台计算机上执行，具体的执行位置是由 master 进行动态调度的，这又大大增加了调试的难度。 为了简化调试、profile 和小规模测试，我们开发了一套 MapReduce 库的本地实现版本，通过使用本地版本的 MapReduce 库，MapReduce 操作在本地计算机上顺序的执行。

#### 状态信息
master 使用嵌入式的 HTTP 服务器(如 Jetty)显示一组状态信息页面，用户可以监控各种执行状态。状 态信息页面显示了包括计算执行的进度，比如已经完成了多少任务、有多少任务正在处理、输入的字节数、 中间数据的字节数、输出的字节数、处理百分比等等。页面还包含了指向每个任务的 stderr 和 stdout 文件的链 接。用户根据这些数据预测计算需要执行大约多长时间、是否需要增加额外的计算资源。这些页面也可以用 来分析什么时候计算执行的比预期的要慢。

#### 计数器
MapReduce 库使用计数器统计不同事件发生次数。比如，用户可能想统计已经处理了多少个单词、已经 索引的多少篇 German 文档等等。为了使用这个特性，用户在程序中创建一个命名的计数器对象，在 Map 和 Reduce 函数中相应的增加计 数器的值。

### 性能

### 经验

### 结束语
